---
Title: "About the Coder"
Author: "Luke Denoncourt"
Date: "Edited 9/8/2021"
Semester: "Fall 2021"
---

![](https://user-images.githubusercontent.com/67921793/132583745-5c8a660d-424e-494c-a5c6-1f26251c1abf.jpg "Yup, that's me. You are probably wondering how I got here, trapped in this computer.")

### Bio 

I am a senior, double majoring in Biology and Data Science. I am currently working on going to graduate school for geomicrobiology/astrobiology.

### Website
www.linkedin.com/in/luke-denoncourt

### Things I like to do

+ Cook
+ Eat
+ Eat what I cook
+ Implement machine learning algorithms to elucidate secrets of the biological world with a goal of understanding life's origin in the universe
+ Pet dogs and cats


### Sample Script
[resnet50_flowering_or_not]()

{
#!/usr/bin/env python
# coding: utf-8
# Last edit: 09/13/2021
# This script runs a ResNet50 model on images of plants to determine if they are flowering
    # I placed a small subset of the data called "image_data_sample" as a walkthrough for this script
    # The data contains images and corresponding labels of flowering or not flowering
    # Place it in the WD and do not mess with it

## Required Packages
from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import time
import ssl
import smtplib
import pandas as pd
import seaborn as sn
import os



## Email setup to alert you of model completion and output info
# For this to work you may need to change your setting 'less ecure app access' to ON
# I made a junk email for this specifically and suggest you do the same
port = 465  # For SSL
smtp_server = "smtp.gmail.com"
email = input('Enter the email that will send and receive the email (you email yourself): ')
sender_email = email  # Enter your address
receiver_email = email  # Enter receiver address
password = input("Type your password and press enter: ")


## Setting up input data for model
print('Setting up input data for model')
model_name = input('Type model name here: ')

HEIGHT__height = 500
WEIGHT__weight = 300


train_batch = int(input('Training batch size: '))
val_batch = int(input('Validation batch size: '))


training_dir = './image_data_sample/training'
validation_dir = './image_data_sample/validation'
testing_dir = './image_data_sample/testing'


train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) # can put data augmentations in here

# Maybe put class mode = binary
train_generator = train_datagen.flow_from_directory(
    training_dir,
    target_size = (HEIGHT__height, WEIGHT__weight),
    batch_size= train_batch
    # 256
)


valid_generator = train_datagen.flow_from_directory(
    validation_dir,
    target_size = (HEIGHT__height, WEIGHT__weight),
    batch_size = val_batch
    #64
)


test_generator = train_datagen.flow_from_directory(
    testing_dir,
    target_size = (HEIGHT__height, WEIGHT__weight),
    batch_size = 1
)


x,y = test_generator.next()
x.shape


## Establishing model
print('Establishing model')
base_model = ResNet50(include_top=False, weights = None)
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation = 'relu')(x)
predictions =Dense(train_generator.num_classes, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)


for layer in base_model.layers:
    layer.trainable=True


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


## Running model
print('Running model')
start = time.time()

num_epochs = int(input('number of epochs: '))
history = model.fit(train_generator, epochs=num_epochs, validation_data = valid_generator)

end = time.time()
minutes = int((end-start)/60)

print('This program took ' + str(minutes) + ' minutes to run')
print('It took ' + str(minutes/num_epochs) + ' minutes per epoch')


test_loss, test_acc = model.evaluate(test_generator, verbose=2)


test_acc = str(test_acc)[:6]


## Getting the validation scores
val_acc = history.history['accuracy']
val_acc = str(val_acc[0])[:6]

model.save(model_name)

## Sending message
message = """Subject: Hi there! I finished running {model_name}.
It had a final validation score of {val_score}
It had a final testing score of {test_score}
This program took {time_min} minutes to run
It took {min_per_epoch} minutes per epoch
Reminder of model hyperparamters:
Number of epochs = {epoch}
Training batch size = {tbs}
Validation batch size = {vbs}
This message is sent from Python.""".format(model_name = model_name,
                                            time_min = minutes,
                                            min_per_epoch = minutes/num_epochs,
                                           val_score = val_acc,
                                           test_score = test_acc,
                                           epoch = num_epochs,
                                           tbs = train_batch,
                                           vbs = val_batch)

context = ssl.create_default_context()
with smtplib.SMTP_SSL(smtp_server, port, context=context) as server:
    server.login(sender_email, password)
    server.sendmail(sender_email, receiver_email, message)




## Pretty sure this works if do more than 1 epoch - retreives and plots the loss and accuracy for each epoch
print('Producing plots detailing model performance')
if num_epochs > 1:

    acc=history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss=history.history['loss']
    val_loss = history.history['val_loss']

    epoch_range = list(range(1, num_epochs +1, 1))

    plt.plot(epoch_range, acc, 'b', label = "Training Accuracy")
    plt.plot(epoch_range, val_acc, 'r', label = "Val Accuracy")
    plt.yscale('linear')
    plt.title('Training and Validation accuracy')
    plt.legend()
    plt.figure()


    plt.plot(epoch_range, loss, 'b', label = "Training Loss")
    plt.plot(epoch_range, val_loss, 'r', label = "Validation Loss")
    plt.yscale('linear')
    plt.title('Training and Valdiation loss')
    plt.legend()
    plt.figure()


## Heatmap to check how well model did for each class. Can be used in different way to see how it did for certain species
model = tf.keras.models.load_model(model_name)
filesnames= test_generator.filenames
nb_samples=len(test_generator)

y_prob=[]
y_act=[]
test_generator.reset()
for _ in range(nb_samples):
    X_test, Y_test = test_generator.next()
    y_prob.append(model.predict(X_test))
    y_act.append(Y_test)

predicted_class = [list(train_generator.class_indices.keys())[i.argmax()] for i in y_prob]
actual_class = [list(train_generator.class_indices.keys())[i.argmax()] for i in y_act]


out_df = pd.DataFrame(np.vstack([predicted_class, actual_class]).T,columns=['predicted_class','actual_class'])
confusion_matrix = pd.crosstab(out_df['actual_class'], out_df['predicted_class'],
                               rownames=['Actual'], colnames=['Predicted'])

sn.heatmap(confusion_matrix, cmap='Blues', annot=True, fmt='d')
plt.show()
print('test accuracy : {}'.format((np.diagonal(confusion_matrix).sum()/confusion_matrix.sum()*100)))
}




